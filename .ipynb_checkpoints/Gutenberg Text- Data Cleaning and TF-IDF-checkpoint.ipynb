{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one morning when gregor samsa woke from troubled dreams he found', 'himself transformed in his bed into a horrible vermin he lay on', 'his armour like back and if he lifted his head a little he could', 'see his brown belly slightly domed and divided by arches into stiff', 'sections the bedding was hardly able to cover it and seemed ready', 'to slide off any moment his many legs pitifully thin compared', 'with the size of the rest of him waved about helplessly as he', 'looked', '', 'what s happened to me he thought it wasn t a dream his room']\n",
      "one morning when gregor samsa woke from troubled dreams he found himself transformed in his bed into\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "file = open(\"Data/Gutenberg_pg5200_clean.txt.txt\", 'r', encoding='utf-8')\n",
    "lines = []\n",
    "for line in file:\n",
    "    lines.append(line)\n",
    "\n",
    "# Mapping any punctuation to space    \n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))    \n",
    "for line_idx, line in enumerate(lines):\n",
    "    line = line.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ')\n",
    "    line = line.translate(translator)\n",
    "    line = line.replace('  ', ' ')\n",
    "    cleaned_line = []\n",
    "    for word in line.split():\n",
    "        word = word.lower()\n",
    "        word = word.replace(word, ''.join(list(map(lambda i:i if i not in string.punctuation else '', word))))\n",
    "        cleaned_line.append(word)\n",
    "    line = ' '.join(cleaned_line)\n",
    "    lines[line_idx] = line \n",
    "\n",
    "print(lines[:10])\n",
    "data = ' '.join(lines)\n",
    "data = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', ' ')\n",
    "\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for word in data.split():\n",
    "    if word not in vocab:\n",
    "        vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing TF-IDF from scratch\n",
    "vocab_count = dict.fromkeys(vocab, 0)\n",
    "for word in data.split():\n",
    "    vocab_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing IDF\n",
    "import math\n",
    "idf_dict = dict.fromkeys(vocab_count.keys(), 0)\n",
    "for line in lines:    \n",
    "    for word in list(set(line.split())):\n",
    "        idf_dict[word] += 1\n",
    "N = len(lines)\n",
    "for word, val in idf_dict.items():\n",
    "    idf_dict[word] = math.log(N / float(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing TF-IDF\n",
    "tfidf_dict = {}\n",
    "for word, val in vocab_count.items():\n",
    "    tfidf_dict[word] = val * idf_dict[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one morning when gregor samsa woke from troubled dreams he found\n",
      "11\n",
      "[238.3812997707337, 98.61475380652796, 228.0736019147494, 566.2619826811884, 139.66504223817162, 13.76076816437201, 336.6032969915413, 7.57353126274595, 13.76076816437201, 797.0634468580033, 65.11156476869738]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Example of tokenized sentence with TF-IDF\n",
    "print(lines[0])\n",
    "print(len(lines[0].split()))\n",
    "tokenized_sent = []\n",
    "for word in lines[0].split():\n",
    "    tokenized_sent.append(tfidf_dict[word])\n",
    "print(tokenized_sent)\n",
    "print(len(tokenized_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_tfidf_dict = {}\n",
    "for word, val in tfidf_dict.items():\n",
    "    inverse_tfidf_dict[val] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "hand\n",
      "when\n",
      "gregor\n",
      "samsa\n",
      "tram\n",
      "from\n",
      "destination\n",
      "tram\n",
      "he\n",
      "playing\n"
     ]
    }
   ],
   "source": [
    "for token in tokenized_sent:\n",
    "    print(inverse_tfidf_dict[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn's TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfidf = tfidf_vectorizer.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              TF-IDF\n",
      "troubled    0.433653\n",
      "woke        0.411342\n",
      "dreams      0.411342\n",
      "found       0.326577\n",
      "morning     0.299260\n",
      "samsa       0.279395\n",
      "when        0.238809\n",
      "one         0.236467\n",
      "from        0.210224\n",
      "gregor      0.159426\n",
      "he          0.129282\n",
      "punished    0.000000\n",
      "public      0.000000\n",
      "pull        0.000000\n",
      "pulled      0.000000\n",
      "provoking   0.000000\n",
      "pulling     0.000000\n",
      "abandoned   0.000000\n",
      "pure        0.000000\n",
      "provincial  0.000000\n",
      "pursue      0.000000\n",
      "push        0.000000\n",
      "pushed      0.000000\n",
      "pushing     0.000000\n",
      "put         0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(tfidf[0].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
