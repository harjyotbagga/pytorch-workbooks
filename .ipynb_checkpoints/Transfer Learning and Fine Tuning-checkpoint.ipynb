{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_classes = 10\n",
    "learning_rate = 1e-3  # Same as 0.01\n",
    "batch_size = 100\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torchvision\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): Identity()\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Freezing the weights of the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Changing the last couple of layers for our dataset\n",
    "model.avgpool = Identity()\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='dataset/', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root='dataset/', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.data.shape)\n",
    "print(test_dataset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at batch 10 is 2.16940\n",
      "Cost at batch 20 is 2.01889\n",
      "Cost at batch 30 is 1.88271\n",
      "Cost at batch 40 is 1.78614\n",
      "Cost at batch 50 is 1.71603\n",
      "Cost at batch 60 is 1.64743\n",
      "Cost at batch 70 is 1.60265\n",
      "Cost at batch 80 is 1.57186\n",
      "Cost at batch 90 is 1.54461\n",
      "Cost at batch 100 is 1.52310\n",
      "Cost at batch 110 is 1.50799\n",
      "Cost at batch 120 is 1.49315\n",
      "Cost at batch 130 is 1.47731\n",
      "Cost at batch 140 is 1.45835\n",
      "Cost at batch 150 is 1.44638\n",
      "Cost at batch 160 is 1.43209\n",
      "Cost at batch 170 is 1.42138\n",
      "Cost at batch 180 is 1.41249\n",
      "Cost at batch 190 is 1.40309\n",
      "Cost at batch 200 is 1.39264\n",
      "Cost at batch 210 is 1.38406\n",
      "Cost at batch 220 is 1.37698\n",
      "Cost at batch 230 is 1.36963\n",
      "Cost at batch 240 is 1.36177\n",
      "Cost at batch 250 is 1.35651\n",
      "Cost at batch 260 is 1.35000\n",
      "Cost at batch 270 is 1.34355\n",
      "Cost at batch 280 is 1.33792\n",
      "Cost at batch 290 is 1.33385\n",
      "Cost at batch 300 is 1.32916\n",
      "Cost at batch 310 is 1.32546\n",
      "Cost at batch 320 is 1.32036\n",
      "Cost at batch 330 is 1.31668\n",
      "Cost at batch 340 is 1.31158\n",
      "Cost at batch 350 is 1.30823\n",
      "Cost at batch 360 is 1.30490\n",
      "Cost at batch 370 is 1.30211\n",
      "Cost at batch 380 is 1.29804\n",
      "Cost at batch 390 is 1.29419\n",
      "Cost at batch 400 is 1.29201\n",
      "Cost at batch 410 is 1.28998\n",
      "Cost at batch 420 is 1.28815\n",
      "Cost at batch 430 is 1.28452\n",
      "Cost at batch 440 is 1.28251\n",
      "Cost at batch 450 is 1.27961\n",
      "Cost at batch 460 is 1.27599\n",
      "Cost at batch 470 is 1.27392\n",
      "Cost at batch 480 is 1.27147\n",
      "Cost at batch 490 is 1.26914\n",
      "Cost at batch 500 is 1.26737\n",
      "Cost at epoch 1 is 1.26737\n",
      "\n",
      "Cost at batch 10 is 1.14453\n",
      "Cost at batch 20 is 1.15566\n",
      "Cost at batch 30 is 1.14311\n",
      "Cost at batch 40 is 1.13109\n",
      "Cost at batch 50 is 1.12413\n",
      "Cost at batch 60 is 1.11963\n",
      "Cost at batch 70 is 1.12171\n",
      "Cost at batch 80 is 1.12156\n",
      "Cost at batch 90 is 1.12215\n",
      "Cost at batch 100 is 1.11694\n",
      "Cost at batch 110 is 1.11814\n",
      "Cost at batch 120 is 1.11388\n",
      "Cost at batch 130 is 1.11398\n",
      "Cost at batch 140 is 1.11336\n",
      "Cost at batch 150 is 1.11239\n",
      "Cost at batch 160 is 1.11243\n",
      "Cost at batch 170 is 1.11632\n",
      "Cost at batch 180 is 1.11771\n",
      "Cost at batch 190 is 1.12065\n",
      "Cost at batch 200 is 1.12256\n",
      "Cost at batch 210 is 1.12048\n",
      "Cost at batch 220 is 1.12118\n",
      "Cost at batch 230 is 1.12177\n",
      "Cost at batch 240 is 1.11970\n",
      "Cost at batch 250 is 1.12017\n",
      "Cost at batch 260 is 1.11826\n",
      "Cost at batch 270 is 1.11544\n",
      "Cost at batch 280 is 1.11441\n",
      "Cost at batch 290 is 1.11318\n",
      "Cost at batch 300 is 1.11450\n",
      "Cost at batch 310 is 1.11394\n",
      "Cost at batch 320 is 1.11337\n",
      "Cost at batch 330 is 1.11233\n",
      "Cost at batch 340 is 1.11186\n",
      "Cost at batch 350 is 1.10975\n",
      "Cost at batch 360 is 1.10913\n",
      "Cost at batch 370 is 1.10937\n",
      "Cost at batch 380 is 1.10910\n",
      "Cost at batch 390 is 1.10884\n",
      "Cost at batch 400 is 1.10955\n",
      "Cost at batch 410 is 1.10913\n",
      "Cost at batch 420 is 1.10906\n",
      "Cost at batch 430 is 1.10982\n",
      "Cost at batch 440 is 1.10986\n",
      "Cost at batch 450 is 1.10846\n",
      "Cost at batch 460 is 1.10798\n",
      "Cost at batch 470 is 1.10796\n",
      "Cost at batch 480 is 1.10798\n",
      "Cost at batch 490 is 1.10788\n",
      "Cost at batch 500 is 1.10704\n",
      "Cost at epoch 2 is 1.10704\n",
      "\n",
      "Training Completed!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        scores = model(data)\n",
    "        loss = loss_function(scores, targets)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        if ((batch_idx+1)%10==0):\n",
    "            print(f'Cost at batch {batch_idx+1} is {sum(losses)/len(losses):.5f}')\n",
    "    print(f'Cost at epoch {epoch+1} is {sum(losses)/len(losses):.5f}')\n",
    "    print()\n",
    "print('Training Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Testing\n",
    "def check_accuracy(loader, model):\n",
    "    model.eval() # Set model into evaluation mode!\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    for data, targets in loader:\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        predicted_output = model(data)\n",
    "        \n",
    "        _, prediction = predicted_output.max(1)\n",
    "        num_samples += predicted_output.size(0)\n",
    "        num_correct += (prediction==targets).sum()\n",
    "\n",
    "    print(f'Correctly identified samples: {num_correct}')\n",
    "    print(f'Total samples: {num_samples}')\n",
    "    print(f'The Validation Accuracy is {num_correct / num_samples * 100.00:.2f}')\n",
    "    model.train() # Setting model back to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Accuracy on Training Data...\n",
      "Correctly identified samples: 31564\n",
      "Total samples: 50000\n",
      "The Validation Accuracy is 63.13\n",
      "\n",
      "Checking Accuracy on Testing Data...\n",
      "Correctly identified samples: 6113\n",
      "Total samples: 10000\n",
      "The Validation Accuracy is 61.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking Accuracy on Training Data...\")\n",
    "check_accuracy(train_loader, model)\n",
    "print()\n",
    "print(\"Checking Accuracy on Testing Data...\")\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Trained Model\n",
    "checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "torch.save(checkpoint, 'Trained Models/CIFAR_10_VGG_FineTuned.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[108  88  62]\n",
      "  [ 67  52  35]\n",
      "  [ 58  43  30]\n",
      "  ...\n",
      "  [ 40  26  23]\n",
      "  [ 40  27  25]\n",
      "  [ 39  28  26]]\n",
      "\n",
      " [[208 187 158]\n",
      "  [162 148 129]\n",
      "  [121 109  95]\n",
      "  ...\n",
      "  [ 55  34  27]\n",
      "  [ 52  32  28]\n",
      "  [ 48  32  26]]\n",
      "\n",
      " [[188 168 157]\n",
      "  [222 212 204]\n",
      "  [238 234 226]\n",
      "  ...\n",
      "  [ 60  41  31]\n",
      "  [ 61  43  33]\n",
      "  [ 62  43  34]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 87  68  57]\n",
      "  [ 98  77  70]\n",
      "  [105  82  73]\n",
      "  ...\n",
      "  [253 253 245]\n",
      "  [255 255 244]\n",
      "  [247 246 231]]\n",
      "\n",
      " [[ 95  72  61]\n",
      "  [102  77  68]\n",
      "  [111  84  71]\n",
      "  ...\n",
      "  [254 251 239]\n",
      "  [255 253 242]\n",
      "  [252 249 235]]\n",
      "\n",
      " [[ 99  70  59]\n",
      "  [107  77  64]\n",
      "  [122  90  71]\n",
      "  ...\n",
      "  [254 248 232]\n",
      "  [253 248 234]\n",
      "  [252 247 232]]] 4\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rand_int = random.randint(0, 50000)\n",
    "data = train_dataset.data[rand_int]\n",
    "target = train_dataset.targets[rand_int]\n",
    "print(data, target)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mapping = {\n",
    "    0: 'airplane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 10: 'truck'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output: deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(data)\n",
    "print(f'Actual output: {image_mapping[target]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: bird\n"
     ]
    }
   ],
   "source": [
    "reshaped_data = np.expand_dims(np.rollaxis(data, 2, 0), axis=0)\n",
    "# print(data.shape)\n",
    "# print(reshaped_data.shape)\n",
    "reshaped_data = reshaped_data.astype(np.float32)\n",
    "data_tensor = torch.from_numpy(reshaped_data)\n",
    "data_tensor.to(device)\n",
    "predicted_out = model(data_tensor)\n",
    "_, predicted_out = predicted_out.max(1)\n",
    "# print(predicted_out.numpy()[0])\n",
    "print(f'Predicted output: {image_mapping[predicted_out.numpy()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
